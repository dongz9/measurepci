\section{Introduction}
\label{sec:intro}

Fast networks with Remote Direct Memory Access (RDMA) are becoming increasingly
popular.  Designing software systems to make the best use of these networks
is an interesting challenge because of the large design space. For example,
a key-value store atop RDMA can be designed with RDMA reads~\cite{Pilaf, FaRM},
RDMA writes~\cite{Kalia:sigcomm2014}, or a combination of both. Finding the
best design, as demonstrated by prior work~\cite{Kalia:sigcomm2014}, depends on
understanding the relative performance of different RDMA operations.

For small messages, the performance of RDMA operations is closely tied to their
behavior at the PCIe level. Avoiding unnecessary PCIe transactions can improve
performance by several factors, and is necessary to obtain the vendor's
advertized performance~\cite{Kalia:sigcomm2014}. Therefore, understanding the
\emph{exact} PCIe behavior of these operations is critical. While prior work
paints a rough picture of this behavior, which is also known through
word-of-mouth in the RDMA community, a measurement-based analysis of this
behavior is not available.

Part of the difficulty in understanding this behavior lies in the perceived
unavailability of PCIe measurement hardware. ASIC-based PCIe analysers are
expensive devices (over 10,000\$ for a PCIe 3.0 x16 analyser) and are not
widely available. However, we find that the PCIe counters found in Intel's
Xeon servers are sufficient for several measurements.

We make the following main contributions:
\begin{itemize}
\item We verify the PCIe behavior of RDMA read and write operations as
described in HERD~\cite{Kalia:sigcomm2014}.
\item We discover that the PCIe behavior of non-batched and batched RDMA
operations is very different, which has implications on their CPU usage and
peak throughput.
\item We discover evidence of a work request cache in Mellanox's RDMA adapters,
and suspect that it is malfunctioning in one adapter generation.
\item We document the working of PCIe counters in Intel's Xeon servers.
\end{itemize}

The rest of this paper is organized as follows. Section~\ref{sec:pcie} presents
a brief overview of PCIe express and InfiniBand/RDMA, and describes the
metrics reported by various PCIe counters. Section~\ref{sec:measurements}
presents the results from our PCIe measurements of different RDMA operations
on two generations of Mellanox's adapters. Section~\ref{sec:related} discusses
some related work. Section~\ref{sec:concl} discusses lines of future work and
concludes.
